# ЁЯУШ р╕Ър╕Чр╕Чр╕╡р╣И 7 : р╕Чр╕др╕йр╕Ор╕╡р╕Вр╕нр╕Зр╣Ар╕Ър╕вр╣Мр╣Бр╕ер╕░р╣Вр╕бр╣Ар╕Фр╕ер╕Бр╕▓р╕гр╕Ир╕│р╣Бр╕Щр╕Б (Naive Bayes)

---

## ЁЯза р╕кр╣Ир╕зр╕Щр╕Чр╕╡р╣И 1 : р╕Чр╕др╕йр╕Ор╕╡р╕Вр╕нр╕Зр╣Ар╕Ър╕вр╣М (BayesтАЩ Theorem)

### ЁЯФ╣ р╕кр╕╣р╕Хр╕гр╕лр╕ер╕▒р╕Б
$$
P(H|E) = \frac{P(E|H) \, P(H)}{P(E)}
$$

| р╕кр╕▒р╕Нр╕ер╕▒р╕Бр╕йр╕Ур╣М        | р╕Др╕зр╕▓р╕бр╕лр╕бр╕▓р╕в                                          |
| :------------ | :------------------------------------------------ |
| $P(H)$        | р╕Др╕зр╕▓р╕бр╕Щр╣Ир╕▓р╕Ир╕░р╣Ар╕Ыр╣Зр╕Щр╕Вр╕нр╕Зр╕кр╕бр╕бр╕Хр╕┤р╕Рр╕▓р╕Щр╕Бр╣Ир╕нр╕Щр╣Ар╕лр╣Зр╕Щр╕лр╕ер╕▒р╕Бр╕Рр╕▓р╕Щ (Prior)         |
| $P(E pipe H)$ | р╕Др╕зр╕▓р╕бр╕Щр╣Ир╕▓р╕Ир╕░р╣Ар╕Ыр╣Зр╕Щр╕Вр╕нр╕Зр╕лр╕ер╕▒р╕Бр╕Рр╕▓р╕Щр╣Ар╕бр╕╖р╣Ир╕нр╕кр╕бр╕бр╕Хр╕┤р╕Рр╕▓р╕Щр╣Ар╕Ыр╣Зр╕Щр╕Ир╕гр╕┤р╕З (Likelihood) |
| $P(E)$        | р╕Др╕зр╕▓р╕бр╕Щр╣Ир╕▓р╕Ир╕░р╣Ар╕Ыр╣Зр╕Щр╕Вр╕нр╕Зр╕лр╕ер╕▒р╕Бр╕Рр╕▓р╕Щр╕Чр╕▒р╣Йр╕Зр╕лр╕бр╕Ф (Evidence)              |
| $P(H pipe E)$ | р╕Др╕зр╕▓р╕бр╕Щр╣Ир╕▓р╕Ир╕░р╣Ар╕Ыр╣Зр╕Щр╕Вр╕нр╕Зр╕кр╕бр╕бр╕Хр╕┤р╕Рр╕▓р╕Щр╣Ар╕бр╕╖р╣Ир╕нр╣Ар╕лр╣Зр╕Щр╕лр╕ер╕▒р╕Бр╕Рр╕▓р╕Щ (Posterior)     |
    
---

### ЁЯФ╣ р╕Хр╕▒р╕зр╕нр╕вр╣Ир╕▓р╕Зр╣Вр╕Ир╕Чр╕вр╣Мр╕Чр╕╡р╣И 1 тАФ р╕Бр╕▓р╕гр╕зр╕┤р╕Щр╕┤р╕Ир╕Йр╕▒р╕вр╣Вр╕гр╕Др╣Др╕Вр╣Йр╕лр╕зр╕▒р╕Фр╣Гр╕лр╕Нр╣И

**р╕Бр╕│р╕лр╕Щр╕Фр╣Гр╕лр╣Й**

- $P(\text{flu}) = 0.05$  
- $P(\text{cough}|\text{flu}) = 0.80$  
- $P(\text{cough}|~\text{flu}) = 0.10$

**р╕Ир╕Зр╕лр╕▓р╕Др╣Ир╕▓ $P(\text{flu}|\text{cough})$**

---

#### тЬЕ р╕Вр╕▒р╣Йр╕Щр╕Хр╕нр╕Щр╕Бр╕▓р╕гр╕Др╕│р╕Щр╕зр╕У

1я╕ПтГг р╕Др╕│р╕Щр╕зр╕У $P(\text{cough})$  

$$
P(\text{cough}) = P(\text{cough}|\text{flu})P(\text{flu}) + P(\text{cough}|~\text{flu})P(~\text{flu})
$$

$$
P(\text{cough}) = (0.80)(0.05) + (0.10)(0.95) = 0.135
$$

---

2я╕ПтГг р╕Др╕│р╕Щр╕зр╕У $P(\text{flu}|\text{cough})$

$$
P(\text{flu}|\text{cough}) = \frac{P(\text{cough}|\text{flu})P(\text{flu})}{P(\text{cough})}
$$

$$
P(\text{flu}|\text{cough}) = \frac{0.80 ├Ч 0.05}{0.135} = 0.296
$$

**ЁЯз╛ р╕кр╕гр╕╕р╕Ыр╕Ьр╕е:**  
р╕бр╕╡р╣Вр╕нр╕Бр╕▓р╕кр╕Ыр╕гр╕░р╕бр╕▓р╕У **29.6%** р╕Чр╕╡р╣Ир╕Ьр╕╣р╣Йр╕Чр╕╡р╣Ир╕бр╕╡р╕нр╕▓р╕Бр╕▓р╕гр╣Др╕нр╕Ир╕░р╣Ар╕Ыр╣Зр╕Щр╣Др╕Вр╣Йр╕лр╕зр╕▒р╕Фр╣Гр╕лр╕Нр╣И

---

## ЁЯзо р╕кр╣Ир╕зр╕Щр╕Чр╕╡р╣И 2 : р╣Вр╕бр╣Ар╕Фр╕е Naive Bayes

### ЁЯФ╣ р╕кр╕бр╕бр╕Хр╕┤р╕Рр╕▓р╕Щр╕лр╕ер╕▒р╕Б (Assumption)
- р╕Др╕╕р╕Ур╕ер╕▒р╕Бр╕йр╕Ур╕░ (features) р╕Чр╕╕р╕Бр╕Хр╕▒р╕зр╣Ар╕Ыр╣Зр╕Щр╕нр╕┤р╕кр╕гр╕░р╕Хр╣Ир╕нр╕Бр╕▒р╕Щр╣Ар╕бр╕╖р╣Ир╕нр╕гр╕╣р╣Йр╕Др╕ер╕▓р╕кр╣Бр╕ер╣Йр╕з (Conditional Independence)
- р╣Гр╕Кр╣Йр╕Чр╕др╕йр╕Ор╕╡р╕Вр╕нр╕Зр╣Ар╕Ър╕вр╣Мр╕Др╕│р╕Щр╕зр╕Ур╕Др╕зр╕▓р╕бр╕Щр╣Ир╕▓р╕Ир╕░р╣Ар╕Ыр╣Зр╕Щр╕Вр╕нр╕Зр╣Бр╕Хр╣Ир╕ер╕░р╕Др╕ер╕▓р╕к р╣Бр╕ер╣Йр╕зр╣Ар╕ер╕╖р╕нр╕Бр╕Др╕ер╕▓р╕кр╕Чр╕╡р╣Ир╕бр╕╡р╕Др╣Ир╕▓ **р╕бр╕▓р╕Бр╕Чр╕╡р╣Ир╕кр╕╕р╕Ф**

---

### ЁЯФ╣ р╕кр╕╣р╕Хр╕г Naive Bayes р╣Бр╕Ър╕Ър╕Чр╕▒р╣Ир╕зр╣Др╕Ы

$$
P(C|f_1, f_2, тАж, f_n) тИЭ P(C) \prod_{i=1}^{n} P(f_i|C)
$$

| р╕кр╕▒р╕Нр╕ер╕▒р╕Бр╕йр╕Ур╣М          | р╕Др╕зр╕▓р╕бр╕лр╕бр╕▓р╕в                                   |
| :-------------- | :----------------------------------------- |
| $C$             | р╕Др╕ер╕▓р╕к р╣Ар╕Кр╣Ир╕Щ spam / not spam                   |
| $f_i$           | р╕Др╕╕р╕Ур╕ер╕▒р╕Бр╕йр╕Ур╕░ р╣Ар╕Кр╣Ир╕Щ р╕Др╕│р╕зр╣Ир╕▓ тАЬfreeтАЭ, тАЬofferтАЭ            |
| $P(C)$          | р╕Др╕зр╕▓р╕бр╕Щр╣Ир╕▓р╕Ир╕░р╣Ар╕Ыр╣Зр╕Щр╕Вр╕нр╕Зр╕Др╕ер╕▓р╕к (Prior)                 |
| $P(f_i pipe C)$ | р╕Др╕зр╕▓р╕бр╕Щр╣Ир╕▓р╕Ир╕░р╣Ар╕Ыр╣Зр╕Щр╕Вр╕нр╕Зр╕Др╕╕р╕Ур╕ер╕▒р╕Бр╕йр╕Ур╕░р╕ар╕▓р╕вр╣Гр╕Хр╣Йр╕Др╕ер╕▓р╕кр╕Щр╕▒р╣Йр╕Щ           |
| $тИЭ$             | р╕кр╕▒р╕Фр╕кр╣Ир╕зр╕Щ (р╣Ар╕Юр╕гр╕▓р╕░р╕Хр╕▒р╕зр╕лр╕▓р╕г P(f) р╣Ар╕Ыр╣Зр╕Щр╕Др╣Ир╕▓р╕Др╕Зр╕Чр╕╡р╣Ир╕кр╕│р╕лр╕гр╕▒р╕Ър╕Чр╕╕р╕Бр╕Др╕ер╕▓р╕к) |

---

### ЁЯФ╣ Laplace Smoothing (р╕Ыр╣Йр╕нр╕Зр╕Бр╕▒р╕Щр╕Др╣Ир╕▓р╕ир╕╣р╕Щр╕вр╣М)

$$
P(word|class) = \frac{count(word,class) + ╬▒}{total\_words\_in\_class + ╬▒V}
$$

| р╕кр╕▒р╕Нр╕ер╕▒р╕Бр╕йр╕Ур╣М | р╕Др╕зр╕▓р╕бр╕лр╕бр╕▓р╕в                             |
| :----- | :----------------------------------- |
| $╬▒$    | р╕Др╣Ир╕▓р╕Ыр╕гр╕▒р╕Ър╕кр╕бр╕╣р╕Ч (р╕бр╕▒р╕Бр╣Гр╕Кр╣Й = 1)                  |
| $V$    | р╕Ир╕│р╕Щр╕зр╕Щр╕Др╕│р╕Чр╕╡р╣Ир╣Ар╕Ыр╣Зр╕Щр╣Др╕Ыр╣Др╕Фр╣Йр╕Чр╕▒р╣Йр╕Зр╕лр╕бр╕Ф (Vocabulary size) |

---

## ЁЯУШ р╕Хр╕▒р╕зр╕нр╕вр╣Ир╕▓р╕Зр╣Вр╕Ир╕Чр╕вр╣Мр╕Чр╕╡р╣И 2 тАФ р╕Хр╕▒р╕зр╕Бр╕гр╕нр╕Зр╕кр╣Бр╕Ыр╕б (Naive Bayes 1 Feature)

**р╕Бр╕│р╕лр╕Щр╕Фр╣Гр╕лр╣Й:**
- $P(spam) = 0.20$
- $P(free|spam) = 0.70$
- $P(free|~spam) = 0.10$

**р╕Ир╕Зр╕лр╕▓р╕Др╕зр╕▓р╕бр╕Щр╣Ир╕▓р╕Ир╕░р╣Ар╕Ыр╣Зр╕Щр╕Чр╕╡р╣Ир╕нр╕╡р╣Ар╕бр╕ер╕Чр╕╡р╣Ир╕бр╕╡р╕Др╕│р╕зр╣Ир╕▓ тАЬfreeтАЭ р╕Ир╕░р╣Ар╕Ыр╣Зр╕Щ spam**

---

### тЬЕ р╕зр╕┤р╕Шр╕╡р╣Бр╕Бр╣Йр╕Чр╕╡р╕ер╕░р╕Вр╕▒р╣Йр╕Щ

1я╕ПтГг р╕Др╕│р╕Щр╕зр╕У $P(free)$  

$$
P(free) = P(free|spam)P(spam) + P(free|~spam)P(~spam)
$$

$$
P(free) = (0.70 ├Ч 0.20) + (0.10 ├Ч 0.80) = 0.22
$$

---

2я╕ПтГг р╕Др╕│р╕Щр╕зр╕У $P(spam|free)$ 

$$
P(spam|free) = \frac{P(free|spam)P(spam)}{P(free)}
$$

$$
P(spam|free) = \frac{0.70 ├Ч 0.20}{0.22} = 0.636
$$

**ЁЯз╛ р╕кр╕гр╕╕р╕Ыр╕Ьр╕е:**  
р╕бр╕╡р╣Вр╕нр╕Бр╕▓р╕кр╕Ыр╕гр╕░р╕бр╕▓р╕У **63.6%** р╕Чр╕╡р╣Ир╕нр╕╡р╣Ар╕бр╕ер╕Чр╕╡р╣Ир╕бр╕╡р╕Др╕│р╕зр╣Ир╕▓ тАЬfreeтАЭ р╕Ир╕░р╣Ар╕Ыр╣Зр╕Щр╕кр╣Бр╕Ыр╕б

---

## ЁЯУШ р╕Хр╕▒р╕зр╕нр╕вр╣Ир╕▓р╕Зр╣Вр╕Ир╕Чр╕вр╣Мр╕Чр╕╡р╣И 3 тАФ Naive Bayes р╕лр╕ер╕▓р╕вр╕Др╕╕р╕Ур╕ер╕▒р╕Бр╕йр╕Ур╕░ (Multi-feature)

### р╕Бр╕│р╕лр╕Щр╕Фр╕Вр╣Йр╕нр╕бр╕╣р╕е

| р╕Ыр╕гр╕░р╣Ар╕ар╕Ч | р╕Ир╕│р╕Щр╕зр╕Щ  | free  |  win  | offer |
| :----- | :---: | :---: | :---: | :---: |
| spam   |   6   |   4   |   3   |   5   |
| ~spam  |   4   |   1   |   0   |   1   |

р╣Гр╕Кр╣Й Laplace smoothing, $╬▒ = 1$

---

### тЬЕ р╕Вр╕▒р╣Йр╕Щр╕Хр╕нр╕Щр╕Чр╕╡р╣И 1: р╕Др╕│р╕Щр╕зр╕У prior

$$
P(spam) = \frac{6}{10} = 0.6, \quad P(~spam) = 0.4
$$

---

### тЬЕ р╕Вр╕▒р╣Йр╕Щр╕Хр╕нр╕Щр╕Чр╕╡р╣И 2: р╕Др╕│р╕Щр╕зр╕У likelihood р╣Бр╕Хр╣Ир╕ер╕░р╕Др╕│

р╕кр╕│р╕лр╕гр╕▒р╕Ъ spam:

$$
P(free|spam) = \frac{4+1}{6+2} = 0.625
$$

$$
P(win|spam) = \frac{3+1}{6+2} = 0.5
$$

$$
P(offer|spam) = \frac{5+1}{6+2} = 0.75
$$

р╕кр╕│р╕лр╕гр╕▒р╕Ъ ~spam:

$$
P(free|~spam) = \frac{1+1}{4+2} = 0.333
$$

$$
P(win|~spam) = \frac{0+1}{4+2} = 0.167
$$

$$
P(offer|~spam) = \frac{1+1}{4+2} = 0.333
$$

---

### тЬЕ р╕Вр╕▒р╣Йр╕Щр╕Хр╕нр╕Щр╕Чр╕╡р╣И 3: р╕Др╕│р╕Щр╕зр╕У posterior р╣Бр╕Ър╕Ър╣Др╕бр╣Ир╕Хр╣Йр╕нр╕З normalize

р╕кр╕│р╕лр╕гр╕▒р╕Ъ spam:

$$
P(spam|f_1,f_2,f_3) тИЭ 0.6 ├Ч 0.625 ├Ч 0.5 ├Ч 0.75 = 0.141
$$

р╕кр╕│р╕лр╕гр╕▒р╕Ъ ~spam:

$$
P(~spam|f_1,f_2,f_3) тИЭ 0.4 ├Ч 0.333 ├Ч 0.167 ├Ч 0.333 = 0.007
$$

---

### тЬЕ р╕Вр╕▒р╣Йр╕Щр╕Хр╕нр╕Щр╕Чр╕╡р╣И 4: р╕кр╕гр╕╕р╕Ыр╕Ьр╕е

р╣Ар╕Юр╕гр╕▓р╕░ $P(spam|f_1,f_2,f_3) > P(~spam|f_1,f_2,f_3)$  
**р╕Чр╕│р╕Щр╕▓р╕вр╕зр╣Ир╕▓р╕нр╕╡р╣Ар╕бр╕ер╕Щр╕╡р╣Йр╣Ар╕Ыр╣Зр╕Щ тАЬSpamтАЭ**

---

## ЁЯзй р╕Хр╕▒р╕зр╕нр╕вр╣Ир╕▓р╕Зр╣Вр╕Ир╕Чр╕вр╣Мр╕Чр╕╡р╣И 4 тАФ р╣Гр╕Кр╣Й Laplace smoothing (╬▒=1, V=3)

**р╕Вр╣Йр╕нр╕бр╕╣р╕е:**  

| р╕Ыр╕гр╕░р╣Ар╕ар╕Ч | offer |  win  | hello |
| :----- | :---: | :---: | :---: |
| spam   |   3   |   2   |   0   |
| ~spam  |   0   |   0   |   4   |

р╕кр╕бр╕бр╕Хр╕┤ $P(spam)=P(~spam)=0.5$

---

### тЬЕ р╕Вр╕▒р╣Йр╕Щр╕Хр╕нр╕Щр╕Чр╕╡р╣И 1: р╕Др╕│р╕Щр╕зр╕Ур╣Бр╕Хр╣Ир╕ер╕░р╕Др╕│

$$
P(hello|spam) = \frac{0+1}{5+1├Ч3} = 0.125
$$

$$
P(offer|spam) = \frac{3+1}{5+1├Ч3} = 0.5
$$

$$
P(hello|~spam) = \frac{4+1}{4+1├Ч3} = 0.714
$$

$$
P(offer|~spam) = \frac{0+1}{4+1├Ч3} = 0.143
$$

---

### тЬЕ р╕Вр╕▒р╣Йр╕Щр╕Хр╕нр╕Щр╕Чр╕╡р╣И 2: р╕Др╕│р╕Щр╕зр╕Ур╕Др╣Ир╕▓р╕гр╕зр╕б

$$
P(spam|hello,offer) тИЭ 0.5 ├Ч 0.125 ├Ч 0.5 = 0.031
$$

$$
P(~spam|hello,offer) тИЭ 0.5 ├Ч 0.714 ├Ч 0.143 = 0.051
$$

---

### тЬЕ р╕Вр╕▒р╣Йр╕Щр╕Хр╕нр╕Щр╕Чр╕╡р╣И 3: Normalize р╣Бр╕ер╕░р╣Ар╕Ыр╕гр╕╡р╕вр╕Ър╣Ар╕Чр╕╡р╕вр╕Ъ

$$
P(spam|hello,offer) = \frac{0.031}{0.031+0.051} = 0.378
$$

$$
P(~spam|hello,offer) = \frac{0.051}{0.031+0.051} = 0.620
$$

**ЁЯз╛ р╕кр╕гр╕╕р╕Ыр╕Ьр╕е:**  
р╣Ар╕бр╕╖р╣Ир╕нр╕бр╕╡р╕Др╕│р╕зр╣Ир╕▓ тАЬhelloтАЭ р╣Бр╕ер╕░ тАЬofferтАЭ тЖТ р╕нр╕╡р╣Ар╕бр╕ер╕Щр╕╡р╣Йр╕бр╕╡р╣Вр╕нр╕Бр╕▓р╕кр╣Ар╕Ыр╣Зр╕Щ тАЬ~SpamтАЭ **62%**

---

## ЁЯзо р╕кр╕гр╕╕р╕Ыр╕кр╕╣р╕Хр╕гр╕Чр╕╡р╣Ир╕Др╕зр╕гр╕гр╕╣р╣Й

| р╕кр╕╣р╕Хр╕г                                              | р╕Кр╕╖р╣Ир╕н                | р╕Др╕│р╕нр╕Шр╕┤р╕Ър╕▓р╕в                   |
| :----------------------------------------------- | :---------------- | :----------------------- |
| $P(H(pipe) E) = \frac{P(E (pipe) H)P(H)}{P(E)}$  | BayesтАЩ Theorem    | р╕Др╕зр╕▓р╕бр╕Щр╣Ир╕▓р╕Ир╕░р╣Ар╕Ыр╣Зр╕Щр╣Бр╕Ър╕Ър╕бр╕╡р╣Ар╕Зр╕╖р╣Ир╕нр╕Щр╣Др╕В    |
| $P(C(pipe) f_1,тАж,f_n) тИЭ P(C)\prod P(f_i(pipe)C)$ | Naive Bayes       | р╕Бр╕▓р╕гр╕Ир╕│р╣Бр╕Щр╕Бр╕лр╕ер╕▓р╕вр╕Др╕╕р╕Ур╕ер╕▒р╕Бр╕йр╕Ур╕░       |
| $P(word (pipe) class)=\frac{count+╬▒}{total+╬▒V}$  | Laplace smoothing | р╕Ыр╣Йр╕нр╕Зр╕Бр╕▒р╕Щр╕Др╣Ир╕▓р╕Др╕зр╕▓р╕бр╕Щр╣Ир╕▓р╕Ир╕░р╣Ар╕Ыр╣Зр╕Щр╣Ар╕Ыр╣Зр╕Щр╕ир╕╣р╕Щр╕вр╣М |

---

> ЁЯТм *тАЬBayes р╣Др╕бр╣Ир╣Др╕Фр╣Йр╕Чр╕│р╕Щр╕▓р╕вр╕нр╕Щр╕▓р╕Др╕Х р╣Бр╕Хр╣Ир╕Кр╣Ир╕зр╕вр╣Ар╕гр╕▓р╕Ыр╕гр╕▒р╕Ър╕Др╕зр╕▓р╕бр╣Ар╕Кр╕╖р╣Ир╕нр╣Ар╕бр╕╖р╣Ир╕нр╕бр╕╡р╕Вр╣Йр╕нр╕бр╕╣р╕ер╣Гр╕лр╕бр╣Ир╣Ар╕Вр╣Йр╕▓р╕бр╕▓тАЭ*
