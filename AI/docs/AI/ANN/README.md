# üß† ‡∏ö‡∏ó‡∏ó‡∏µ‡πà 9 ‚Äî ‡πÇ‡∏Ñ‡∏£‡∏á‡∏Ç‡πà‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ó‡πÄ‡∏ó‡∏µ‡∏¢‡∏° (Artificial Neural Network)

---

## üìò ‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç (Key Terms)

| ‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå | ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢ |
|:--|:--|
| **Neuron (‡∏ô‡∏¥‡∏ß‡∏£‡∏≠‡∏ô)** | ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏¢‡πà‡∏≠‡∏¢‡πÉ‡∏ô‡πÇ‡∏Ñ‡∏£‡∏á‡∏Ç‡πà‡∏≤‡∏¢ ‡∏£‡∏±‡∏ö‡∏≠‡∏¥‡∏ô‡∏û‡∏∏‡∏ï ‡∏Ñ‡∏π‡∏ì‡∏î‡πâ‡∏ß‡∏¢‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å ‡∏ö‡∏ß‡∏Å‡πÑ‡∏ö‡πÅ‡∏≠‡∏™ ‡πÅ‡∏•‡πâ‡∏ß‡∏™‡πà‡∏á‡∏ú‡πà‡∏≤‡∏ô‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Å‡∏£‡∏∞‡∏ï‡∏∏‡πâ‡∏ô |
| **Weight (‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å, w)** | ‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Ç‡∏≠‡∏á‡∏≠‡∏¥‡∏ô‡∏û‡∏∏‡∏ï‡∏ï‡πà‡∏≠‡πÄ‡∏≠‡∏≤‡∏ï‡πå‡∏û‡∏∏‡∏ï |
| **Bias (‡πÑ‡∏ö‡πÅ‡∏≠‡∏™, b)** | ‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏á‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÄ‡∏™‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à ‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏ú‡πà‡∏≤‡∏ô‡∏à‡∏∏‡∏î‡∏®‡∏π‡∏ô‡∏¢‡πå |
| **Activation Function (‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Å‡∏£‡∏∞‡∏ï‡∏∏‡πâ‡∏ô)** | ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡πà‡∏≤‡∏ú‡∏•‡∏£‡∏ß‡∏°‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏™‡πâ‡∏ô‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏ö‡∏ö‡πÑ‡∏°‡πà‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏™‡πâ‡∏ô ‡πÄ‡∏ä‡πà‡∏ô Sigmoid, ReLU |
| **Feed Forward** | ‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏ä‡∏±‡πâ‡∏ô‡∏≠‡∏¥‡∏ô‡∏û‡∏∏‡∏ï ‚Üí ‡∏ä‡∏±‡πâ‡∏ô‡∏ã‡πà‡∏≠‡∏ô ‚Üí ‡∏ä‡∏±‡πâ‡∏ô‡πÄ‡∏≠‡∏≤‡∏ï‡πå‡∏û‡∏∏‡∏ï |
| **Backpropagation** | ‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏¢‡πâ‡∏≠‡∏ô‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î ‡πÇ‡∏î‡∏¢‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° |
| **Loss Function** | ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ß‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡∏≤‡∏î‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Ñ‡πà‡∏≤‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Å‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡∏à‡∏£‡∏¥‡∏á ‡πÄ‡∏ä‡πà‡∏ô MSE |
| **Epoch** | ‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏£‡∏≠‡∏ö‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î |
| **Underfitting** | ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏ô‡πâ‡∏≠‡∏¢‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏¥‡∏î‡∏ó‡∏±‡πâ‡∏á training ‡πÅ‡∏•‡∏∞ test |
| **Overfitting** | ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏°‡∏≤‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ ‡∏à‡∏≥‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ù‡∏∂‡∏Å‡∏à‡∏ô‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà‡πÑ‡∏î‡πâ |

---

## ‚öôÔ∏è ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 1 : ‡∏™‡∏°‡∏Å‡∏≤‡∏£‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡∏ô‡∏¥‡∏ß‡∏£‡∏≠‡∏ô

### ‚úÖ ‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ú‡∏•‡∏£‡∏ß‡∏°‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏™‡πâ‡∏ô (Weighted Sum)
$$
z = \sum_{i=1}^{n} w_i x_i + b
$$

| ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£ | ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢ |
|:--|:--|
| $x_i$ | ‡∏≠‡∏¥‡∏ô‡∏û‡∏∏‡∏ï‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏ó‡∏µ‡πà $i$ |
| $w_i$ | ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏Ç‡∏≠‡∏á‡∏≠‡∏¥‡∏ô‡∏û‡∏∏‡∏ï $x_i$ |
| $b$ | ‡πÑ‡∏ö‡πÅ‡∏≠‡∏™ |
| $n$ | ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏≠‡∏¥‡∏ô‡∏û‡∏∏‡∏ï‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î |

---

### ‚úÖ ‡∏Å‡∏≤‡∏£‡∏™‡πà‡∏á‡∏ú‡πà‡∏≤‡∏ô‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Å‡∏£‡∏∞‡∏ï‡∏∏‡πâ‡∏ô (Activation)
$$
y = f(z)
$$

‡πÄ‡∏ä‡πà‡∏ô ‡∏´‡∏≤‡∏Å‡πÉ‡∏ä‡πâ **Sigmoid Function**  
$$
œÉ(x) = \frac{1}{1 + e^{-x}}
$$

‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏∞‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á 0‚Äì1 ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÄ‡∏ä‡∏¥‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô (Binary Classification)

---

## üßÆ ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 2 : ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÇ‡∏Ñ‡∏£‡∏á‡∏Ç‡πà‡∏≤‡∏¢‡∏ô‡∏¥‡∏ß‡∏£‡∏≠‡∏ô

‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á:  
- ‡∏ä‡∏±‡πâ‡∏ô‡∏≠‡∏¥‡∏ô‡∏û‡∏∏‡∏ï (Input Layer): 3 ‡∏ï‡∏±‡∏ß ($x_1, x_2, x_3$)  
- ‡∏ô‡∏¥‡∏ß‡∏£‡∏≠‡∏ô‡∏ä‡∏±‡πâ‡∏ô‡∏ã‡πà‡∏≠‡∏ô (Hidden Neuron): 1 ‡∏ï‡∏±‡∏ß  
- ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Å‡∏£‡∏∞‡∏ï‡∏∏‡πâ‡∏ô: Sigmoid  

---

### ‚úÖ ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ó‡∏µ‡∏•‡∏∞‡∏Ç‡∏±‡πâ‡∏ô

**1Ô∏è‚É£ ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì z (Weighted Sum):**

$$
z = x_1w_1 + x_2w_2 + x_3w_3 + b
$$

**2Ô∏è‚É£ ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ú‡πà‡∏≤‡∏ô‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô Sigmoid:**

$$
a = \frac{1}{1 + e^{-z}}
$$

**3Ô∏è‚É£ ‡πÅ‡∏õ‡∏•‡∏ú‡∏•:**  
- ‡∏ñ‡πâ‡∏≤ $a > 0.5$ ‚Üí ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏•‡∏≤‡∏™ 1  
- ‡∏ñ‡πâ‡∏≤ $a < 0.5$ ‚Üí ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏•‡∏≤‡∏™ 0

---

### üí° ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÇ‡∏à‡∏ó‡∏¢‡πå‡∏ó‡∏µ‡πà 1 ‚Äî ‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å‡∏ô‡∏¥‡∏ß‡∏£‡∏≠‡∏ô‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏ï‡∏±‡∏ß

**‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÉ‡∏´‡πâ**
| ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£ | ‡∏Ñ‡πà‡∏≤ |
|:--|:--|
| $x_1=0.5$ | $w_1=0.4$ |
| $x_2=0.8$ | $w_2=0.6$ |
| $x_3=0.3$ | $w_3=0.9$ |
| $b = 0.2$ | ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Å‡∏£‡∏∞‡∏ï‡∏∏‡πâ‡∏ô = Sigmoid |

---

**‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 1:**  
‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤ $z$

$$
z = (0.5√ó0.4) + (0.8√ó0.6) + (0.3√ó0.9) + 0.2
$$
$$
z = 0.2 + 0.48 + 0.27 + 0.2 = 1.15
$$

---

**‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 2:**  
‡∏™‡πà‡∏á‡∏ú‡πà‡∏≤‡∏ô‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô Sigmoid
$$
a = \frac{1}{1+e^{-1.15}} ‚âà 0.759
$$

**‚úÖ ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö:**  
‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Ç‡∏≠‡∏á‡∏ô‡∏¥‡∏ß‡∏£‡∏≠‡∏ô‡∏Ñ‡∏∑‡∏≠ **0.759**  
‡∏´‡∏£‡∏∑‡∏≠‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô ~75.9% ‡∏ó‡∏µ‡πà‡∏≠‡∏¥‡∏ô‡∏û‡∏∏‡∏ï‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏•‡∏≤‡∏™ 1

---

## ‚öôÔ∏è ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 3 : ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡πÅ‡∏•‡∏∞‡πÑ‡∏ö‡πÅ‡∏≠‡∏™ (Gradient Descent + Backpropagation)

‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏Å‡∏¥‡∏î‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£ **‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î (Loss)** ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏ï‡∏≤‡∏°‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á‡∏Ç‡∏≠‡∏á **Gradient**

---

### ‚úÖ ‡∏™‡∏°‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å
$$
w := w - Œ± \frac{‚àÇL}{‚àÇw}
$$
$$
b := b - Œ± \frac{‚àÇL}{‚àÇb}
$$

| ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£ | ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢ |
|:--|:--|
| $Œ±$ | Learning Rate (‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ) |
| $\frac{‚àÇL}{‚àÇw}$ | ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏±‡∏ô‡∏Ç‡∏≠‡∏á Loss ‡∏ï‡πà‡∏≠‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå |

---

### ‚úÖ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ß‡∏±‡∏î‡∏Ñ‡πà‡∏≤‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î (Loss Function)
‡∏Å‡∏£‡∏ì‡∏µ Binary Classification ‡πÉ‡∏ä‡πâ:
$$
L = \frac{1}{2}(y - \hat{y})^2
$$
‡∏´‡∏£‡∏∑‡∏≠
$$
L = -[y \log(\hat{y}) + (1-y)\log(1-\hat{y})]
$$

---

### üí° ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÇ‡∏à‡∏ó‡∏¢‡πå‡∏ó‡∏µ‡πà 2 ‚Äî ‡∏õ‡∏£‡∏±‡∏ö‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏î‡πâ‡∏ß‡∏¢ Gradient Descent

**‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÉ‡∏´‡πâ**
- ‡∏≠‡∏¥‡∏ô‡∏û‡∏∏‡∏ï $x = 0.5$
- ‡∏Ñ‡πà‡∏≤‡∏à‡∏£‡∏¥‡∏á $y = 1$
- ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô $w = 0.4$
- ‡πÑ‡∏ö‡πÅ‡∏≠‡∏™ $b = 0.1$
- ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ $Œ± = 0.1$
- ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Å‡∏£‡∏∞‡∏ï‡∏∏‡πâ‡∏ô = Sigmoid

---

#### ‚úÖ ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 1: ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Forward Pass
$$
z = wx + b = (0.4)(0.5) + 0.1 = 0.3
$$
$$
\hat{y} = \frac{1}{1+e^{-0.3}} = 0.574
$$

---

#### ‚úÖ ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 2: ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î (Loss)
$$
L = \frac{1}{2}(y - \hat{y})^2 = 0.5(1 - 0.574)^2 = 0.091
$$

---

#### ‚úÖ ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 3: ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Gradient
‡∏≠‡∏ô‡∏∏‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏Ç‡∏≠‡∏á‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô Sigmoid:
$$
œÉ'(z) = œÉ(z)(1 - œÉ(z))
$$
‡∏î‡∏±‡∏á‡∏ô‡∏±‡πâ‡∏ô:
$$
œÉ'(0.3) = 0.574(1 - 0.574) = 0.244
$$

‡∏´‡∏≤‡∏≠‡∏ô‡∏∏‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏Ç‡∏≠‡∏á Loss ‡∏ï‡πà‡∏≠ $w$:
$$
\frac{‚àÇL}{‚àÇw} = (y - \hat{y})(-1)œÉ'(z)x
$$
‡πÅ‡∏ó‡∏ô‡∏Ñ‡πà‡∏≤:
$$
\frac{‚àÇL}{‚àÇw} = (1 - 0.574)(-1)(0.244)(0.5) = -0.052
$$

---

#### ‚úÖ ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 4: ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å
$$
w := w - Œ± \frac{‚àÇL}{‚àÇw}
$$
$$
w = 0.4 - 0.1(-0.052) = 0.4052
$$

---

#### ‚úÖ ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 5: ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÑ‡∏ö‡πÅ‡∏≠‡∏™
$$
\frac{‚àÇL}{‚àÇb} = (y - \hat{y})(-1)œÉ'(z)
$$
$$
\frac{‚àÇL}{‚àÇb} = (1 - 0.574)(-1)(0.244) = -0.104
$$
$$
b := b - Œ± \frac{‚àÇL}{‚àÇb}
$$
$$
b = 0.1 - 0.1(-0.104) = 0.1104
$$

---

**‚úÖ ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö:**  
‡∏´‡∏•‡∏±‡∏á‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏£‡∏≠‡∏ö  
$$
w = 0.4052, \quad b = 0.1104
$$
Loss ‡∏•‡∏î‡∏•‡∏á ‚Üí ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô

---

## üìä ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 4 : ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•

| ‡∏ï‡∏±‡∏ß‡∏ä‡∏µ‡πâ‡∏ß‡∏±‡∏î | ‡∏™‡∏π‡∏ï‡∏£ | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ |
|:--|:--|:--|
| **Accuracy** | $(TP + TN) / (TP + TN + FP + FN)$ | ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏ó‡∏≤‡∏¢‡∏ñ‡∏π‡∏Å‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î |
| **Precision** | $TP / (TP + FP)$ | ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Ñ‡∏•‡∏≤‡∏™ 1 |
| **Recall** | $TP / (TP + FN)$ | ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Ñ‡∏•‡∏≤‡∏™ 1 |
| **F1-score** | $2 √ó \frac{Precision √ó Recall}{Precision + Recall}$ | ‡∏Ñ‡πà‡∏≤‡∏Å‡∏•‡∏≤‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á Precision ‡πÅ‡∏•‡∏∞ Recall |

---

## üîç ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 5 : ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ü‡∏¥‡∏ï‡πÇ‡∏°‡πÄ‡∏î‡∏•

| ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó | ‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞ | ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á |
|:--|:--|:--|
| Underfitting | ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏á‡πà‡∏≤‡∏¢‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ | ‡πÉ‡∏ä‡πâ Perceptron ‡∏ä‡∏±‡πâ‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏£‡∏π‡∏õ‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ |
| Appropriate fitting | ‡∏û‡∏≠‡∏î‡∏µ | Accuracy ‡πÅ‡∏•‡∏∞ F1-score ‡∏™‡∏π‡∏á‡∏ó‡∏±‡πâ‡∏á Train/Test |
| Overfitting | ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ | ‡∏à‡∏≥‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ù‡∏∂‡∏Å, ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà‡∏ú‡∏¥‡∏î‡∏ö‡πà‡∏≠‡∏¢ |

---

> üí¨ *‚ÄúNeural Networks ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏â‡∏•‡∏≤‡∏î‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏°‡∏±‡∏ô‡∏£‡∏π‡πâ‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á ‡πÅ‡∏ï‡πà‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏°‡∏±‡∏ô‡∏õ‡∏£‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÑ‡∏î‡πâ‚Äù*
