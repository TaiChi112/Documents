## AI Agent Environment Terminology

### สภาพแวดล้อมของเอเจนต์

- **Fully Observable** vs **Partially Observable**
  - **Fully Observable**: สภาพแวดล้อมที่เอเจนต์สามารถรับรู้สถานะทั้งหมดได้อย่างสมบูรณ์
    - *ตัวอย่าง*: เกมหมากรุกที่เห็นตำแหน่งของหมากทุกตัวบนกระดาน
  - **Partially Observable**: สภาพแวดล้อมที่เอเจนต์รับรู้สถานะได้เพียงบางส่วน
    - *ตัวอย่าง*: เกมโป๊กเกอร์ที่ไม่รู้ไพ่ของคู่ต่อสู้, รถไร้คนขับที่เห็นเฉพาะสภาพแวดล้อมผ่านกล้องและเซ็นเซอร์

- **Deterministic** vs **Stochastic**
  - **Deterministic**: สภาพแวดล้อมที่ผลลัพธ์ของการกระทำมีความแน่นอน สถานะถัดไปขึ้นอยู่กับสถานะปัจจุบันและการกระทำเท่านั้น
    - *ตัวอย่าง*: เกมหมากรุกที่การเดินหมากแต่ละครั้งมีผลลัพธ์แน่นอน
  - **Stochastic**: สภาพแวดล้อมที่มีความไม่แน่นอน ผลลัพธ์ของการกระทำอาจเป็นไปได้หลายแบบ
    - *ตัวอย่าง*: การเล่นไพ่ที่มีการสับไพ่, การขับรถในสภาพอากาศที่ไม่แน่นอน

- **Episodic** vs **Sequential**
  - **Episodic**: สภาพแวดล้อมที่ประสบการณ์ถูกแบ่งเป็นตอนๆ แต่ละตอนเป็นอิสระจากกัน
    - *ตัวอย่าง*: การตรวจสอบผลิตภัณฑ์ที่สายพานการผลิต แต่ละชิ้นเป็นอิสระจากกัน
  - **Sequential**: สภาพแวดล้อมที่การตัดสินใจในปัจจุบันส่งผลต่อสถานการณ์ในอนาคต
    - *ตัวอย่าง*: เกมหมากรุกที่ต้องวางแผนหลายตาล่วงหน้า, การวางแผนเส้นทางของรถไร้คนขับ

- **Static** vs **Dynamic**
  - **Static**: สภาพแวดล้อมที่ไม่เปลี่ยนแปลงระหว่างที่เอเจนต์กำลังคิด
    - *ตัวอย่าง*: เกมปริศนาอย่างซูโดกุที่ไม่มีการเปลี่ยนแปลงขณะผู้เล่นคิด
  - **Dynamic**: สภาพแวดล้อมที่เปลี่ยนแปลงได้ตลอดเวลาแม้เอเจนต์ไม่ได้กระทำการใดๆ
    - *ตัวอย่าง*: เกมเรียลไทม์อย่าง Starcraft, การขับรถในถนนที่มีรถคันอื่นเคลื่อนที่

- **Discrete** vs **Continuous**
  - **Discrete**: สภาพแวดล้อมที่มีจำนวนสถานะและการกระทำที่จำกัดและชัดเจน
    - *ตัวอย่าง*: เกมหมากรุกที่มีจำนวนตำแหน่งหมากและการเดินที่จำกัด
  - **Continuous**: สภาพแวดล้อมที่มีสถานะและการกระทำเป็นค่าต่อเนื่อง
    - *ตัวอย่าง*: การควบคุมรถไร้คนขับที่ต้องปรับมุมพวงมาลัยและความเร็วอย่างต่อเนื่อง

- **Single-agent** vs **Multi-agent**
  - **Single-agent**: สภาพแวดล้อมที่มีเอเจนต์เพียงตัวเดียวทำงานอยู่
    - *ตัวอย่าง*: หุ่นยนต์ดูดฝุ่นที่ทำงานคนเดียวในบ้าน, เกมปริศนาอย่าง Sudoku
  - **Multi-agent**: สภาพแวดล้อมที่มีเอเจนต์หลายตัวทำงานร่วมกันหรือแข่งขันกัน
    - *ตัวอย่าง*: เกมหมากรุกที่มีสองฝ่ายแข่งขันกัน, ตลาดหุ้นที่มีเอเจนต์ซื้อขายหลายตัว

- **Benign** vs **Adversarial**
  - **Benign**: สภาพแวดล้อมที่ไม่มีเจตนาขัดขวางความสำเร็จของเอเจนต์
    - *ตัวอย่าง*: หุ่นยนต์ดูดฝุ่นในบ้านที่ไม่มีใครพยายามขัดขวาง
  - **Adversarial**: สภาพแวดล้อมที่มีเอเจนต์อื่นพยายามขัดขวางความสำเร็จของเอเจนต์
    - *ตัวอย่าง*: เกมหมากรุกที่คู่แข่งพยายามเอาชนะ, ระบบความปลอดภัยที่ต้องรับมือกับแฮกเกอร์

### คำศัพท์พื้นฐานอื่นๆ เกี่ยวกับ AI Agent

- **Agent**: ระบบอัตโนมัติที่สามารถรับรู้สภาพแวดล้อมผ่านเซ็นเซอร์และกระทำการผ่านตัวขับเคลื่อน
  - *ตัวอย่าง*: หุ่นยนต์ดูดฝุ่นอัตโนมัติ, ผู้ช่วยเสมือนอย่าง Siri หรือ Alexa

- **Perception**: การรับรู้หรือการสังเกตสภาพแวดล้อมของเอเจนต์ผ่านเซ็นเซอร์
  - *ตัวอย่าง*: กล้องและเรดาร์บนรถยนต์ไร้คนขับ, ไมโครโฟนที่รับเสียงคำสั่ง

- **Action**: การกระทำที่เอเจนต์ทำเพื่อเปลี่ยนแปลงสภาพแวดล้อมหรือสถานะของตัวเอง
  - *ตัวอย่าง*: การหมุนพวงมาลัยของรถไร้คนขับ, การตอบคำถามของผู้ช่วยเสมือน

- **Reward**: ค่าที่บ่งบอกว่าการกระทำของเอเจนต์ดีหรือไม่ดีในสถานการณ์นั้นๆ
  - *ตัวอย่าง*: คะแนนบวกเมื่อหุ่นยนต์ดูดฝุ่นเก็บขยะได้, คะแนนลบเมื่อรถยนต์ไร้คนขับชนวัตถุ

- **Policy**: กลยุทธ์หรือกฎการตัดสินใจที่เอเจนต์ใช้เพื่อเลือกการกระทำในแต่ละสถานะ
  - *ตัวอย่าง*: กฎการหลบสิ่งกีดขวางของหุ่นยนต์, กลยุทธ์การเล่นหมากรุกที่เลือกเดินหมากที่ได้ประโยชน์สูงสุด